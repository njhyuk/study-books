# 분산 메시지큐
* 메시지 큐를 사용하면 얻는 이점
  * 결합도 완화
  * 규모 확장성 개선 : consumer 만 확장
  * 가용성 개선 : 장애 컴포넌트 제외 동작
  * 성능 개선 : 비동기 통신
* 메시지 큐 vs 이벤트 스트리밍 플랫폼
  * RabbitMQ 도 스트리밍 기능이 있어 차이가 희미해짐
    * 메시지를 반복 소비
    * 데이터의 장기 보관
## 1단계: 문제 이해 및 설계 범위 확정
* 메시지의 형태와 평균 크기 : 수 KB 가정
* 멀티미디어 지원 여부 : 텍스트만 지원
* 메시지 반복 소비 기능 : 하나의 메시지를 여러 소비자가 수신 하도록 (전통적 MQ는 한 소비자가 받으면 지움)
* 소비 순서 : 생산된 순서 그대로
* 데이터의 지속성 : 2주
* 메시지 전달 방식 : 최대한번/최소한번/정확히한번
* 대역폭 : 높은 수준의 대역폭 제공
* 지연 : 낮은 전송 지연
### 기능 요구사항
* 생산자는 메시지 큐에 메시지를 보낼 수 있어야함
* 소비자는 메시지 큐를 통해 수신 할 수 있어야함
* 메시지는 반복적으로 수신할 수도 있고, 단 한번만 수신할 수 있음
* 오래된 이력 데이터는 삭제될 수 있음
* 메시지 크기는 KB 수준
* 메시지가 생산된 순서되로 소비자에게 전달
* 메시지 전달 방식은 최소 한번, 최대 한번, 정확히 한번 가운데 설정 할 수 있어야함
[Apache Kafka 에서 정확히 한 번(Exactly-once)이 가능한가?](https://barunmo.blogspot.com/2017/07/apache-kafka-exactly-once.html)
[Kafka의 정확히 한 번 전달\(exactly-once delivery\)](https://devs0n.tistory.com/74)
### 비기능 요구사항
* 높은 대역폭과 낮은 전송 지연 가운데 하나를 설정으로 선택 가능하게 하는 기능
* 규모 확장성, 메시지 양이 급증해도 처리 가능
* 지속성 및 내구성, 데이터는 디스크에 지속적 보관, 여러 노드에 복제
### 전통적 메시지 큐와 다른점
* 전통적 메시지 큐는 메시지 보관 문제를 중요하게 다루지 않음
* 메시지 전달 순서를 보존하지 않음
## 2단계 : 개략적 설계안 제시 및 동의 구하기
![](chapter4/image.png)
### 메시지 모델
* 일대일 모델
  * 한 소비자만 소비 가능
  * 소비자가 메시지를 가져갔다고 알리면 큐에서 삭제
  * 본 설계안은 2주간 지속, 반복 소비 가능, 발행-구독이 더 자연스러움
* 발행-구독 모델
  * 토픽이라는 개념이 도입 되어야함
  * 토픽에 전달된 메시지는, 토픽을 구독하는 소비자에게 모두 전달됨
  * ![](chapter4/image%202.png)<!-- {"width":468} -->
#### 토픽, 파티션, 브로커
* 토픽에 보관되는 데이터 양이 커져서 서버 한대로 어려워지면?
* 파티션, 즉 샤딩 기법으로 해결
* 토픽을 여러 파티션으로 분할해서 모든 파티션에 균등하게 나눠 보내기
* 토픽의 용량을 확장하고 싶으면 파티션 개수 늘리기
![](chapter4/image%203.png)<!-- {"width":523} -->
* 파티션을 유지하는 서버는 **브로커**
* 각 파티션은 FIFO 큐처럼 동작
  * 같은 파티션 안에서는 메시지 순서 유지
* 파티션 내에서의 메시지 위치는 **오프셋**
* 생산자의 메시지는 토픽의 파티션중 하나에 보내짐
* 메시지에는 사용자 ID 키를 붙일 수 있음
  * 같은 키를 가지면 같은 파티션으로 보내짐
* 소비자가 여럿이면 각 구독자는 파티션의 일부를 담당
#### 소비자 그룹
![](chapter4/image%204.png)<!-- {"width":490} -->
* 같은 그룹 내의 소비자는 메시지를 병렬로 소비
  * 문제 : 메시지를 순서대로 소비하는게 불가능
    * 어떤 파티션의 메시지는 한 그룹 안에서는 오직 한 소비자만 읽을수 있게 하면 됨
      * 토픽의 파티션보다 소비자의 수가 크면 해당 토픽에서 데이터를 읽을 수 없음
> 한 파티션 내의 순서는 보장하지만, 여러개 파티션간의 item 들의 순서 보장이 필요한 경우,
> consume 이후 RDB 적재 -> RDB 조회시 정렬하는 방법 사용 [kafka 순서 보장](https://umbum.dev/1314/)
#### 개략적 설계안 
![](chapter4/image%205.png)<!-- {"width":532} -->
* 클라이언트
  * 생산자 : 메시지를 보냄
  * 소비자 그룹 : 토픽 구독, 메시지 소비
* 핵심 서비스 및 저장소
  * 브로커
    * 파티션 유지, 하나의 파티션은 특정 토픽에 대한 메시지의 부분집합 유지
  * 저장소
    * 데이터 저장소 : 메시지는 파티션 내 데이터 저장소에 보관
    * 상태 저장소 : 소비자 상태는 이 저장소에 유지
    * 메타데이터 저장소 : 토픽 설정, 토픽 속성
  * 조정 서비스
    * 서비스 탐색 : 살아있는 브로커 확인
    * 리더 선출 : 브로커중 하나는 컨트롤러 역할 담당
    * 아파치 주키퍼 : 컨트롤러 선출을 담당
## 3단계: 상세 설계
### 데이터 저장소
* 메시지 큐의 트래픽 패턴
  * 읽기와 쓰기가 빈번함
  * 갱신/삭제 연산은 발생하지 않음 (지속보관)
  * 순차적인 읽기/쓰기가 대부분
* 선택지 1 : 데이터베이스
  * RDB : 토픽별로 테이블
  * Nosql : 토픽별로 컬렉션
  * DB는 오히려 시스템 병목이 될 수 있음
    * 읽기와 쓰기가 동시에 대규모로 빈번함
* 선택지 2 : 쓰기 우선 로그 (WAL)
  * append-only 일반 파일
  * 아파치 주키퍼, Mysql의 복구 로그도 WAL
  * WAL 은 읽기/쓰기가 순차적일때 좋은 성능
  * 회전식 디스크 기반 저장장치는 큰용량을 저렴한 가격에 제공
  * ![](chapter4/image%206.png)<!-- {"width":506} -->
    * 새로운 메시지는 파티션 꼬리 부분에 추가됨
    * 오프셋은 그 결과로 점진적 증가
    * 로그 파일의 줄 번호를 오프셋으로 사용
      * 단, 무한정으로 파일 하나를 쓸 수 없음
      * 세그먼트 단위로 나누자
      * 세그먼트 크기가 한계에 도달하면 새 세그먼트 파일에만 씀
      * ![](chapter4/image%207.png)<!-- {"width":367} -->
#### 디스크 성능 유의사항
* 디스크가 느리다는것은 널리 퍼진 편견
  * 정말로 느릴땐 데이터 접근 패턴이 무작위 일떄
  * 순차적 데이터 접근 패턴의 자료구조를 사용하면 매우 빠르고 저렴
  * 필요하다면 메모리 전불르 디스크 데이터 캐시 (WAL 기능)
### 메시지 자료 구조
![](chapter4/image%208.png)<!-- {"width":245} -->
* key : 파티션을 정할때 사용, 없으면 무작위
* value : payload (회사에서 여기에 header, body를 정의하기도)
### 일괄 처리
* 여러메시지를 한번에 네트워크 요청으로 전송 (네트워크 비용 절감)
* 브로커가 여러 메시지를 한번에 로그에 기록
  * 운영체제가 관리하는 디스크 캐시에 연속된 공간 점유 가능, 높은 대역폭
* 낮은 응답 지연이 중요하다면?
  * 배치 전송을 낮춰야함. 모으는데 시간 걸림.
    * 그러면 디스크 성능이 내려감 Trade Off
  * 처리량을 높이려면 토픽당 파티션 수 늘리기
### 생산자 측 작업 흐름
* 생산자의 메세지는 라우팅 계층 (리더 브로커) 가 적절한 브로커에 메세지를 보냄
![](chapter4/image%209.png)<!-- {"width":367} -->
* 충분한 사본이 동기화 되면 리더는 데이터를 디스크에 기록 (commit)
  * 데이터가 소비 가능 상태가 됨
* 단점
  * 라우팅 계층으로 인해 네트워크 오버헤드
  * 일괄 처리는 고려하지 않은 설계
  * 아래 수정 설계안으로 해결
![](chapter4/image%2010.png)<!-- {"width":353} -->
* 라우팅 계층을 생산자 내부로 편입, 버퍼 도입 (클라이언트 라이브러리)
### 소비자 측 작업 흐름
![](chapter4/image%2011.png)<!-- {"width":570} -->
* 푸시 모델
  * 장점
    * 낮은 지연 : 브로커는 메시지를 받는 즉시 소비자에게 보냄
  * 단점
    * 소비자가 메시지를 처리하는 속도가 생산자가 메시지를 만드는 속도를 못 따라오면 병목
* 풀 모델
  * 장점
    * 소비자가 소비하는 속도 결정 (소비자 별로 배치 여부 결정)
    * 소비자를 늘려서 해결할 수 있음, 또는 기다려도 됨
    * 일괄처리에 적합
  * 단점
    * 브로커에 메시지가 없어도 소비자는 계속 데이터를 끌어가려고 시도
    * 대신 일반적으로 롱 폴링 모드를 지원함
* 대부분의 메시지 큐는 푸시보단 풀 모델 사용
#### 소비자 재조정 (컨슈머 리밸런싱)
* 트리거
  * 새로운 소비자 합류, 기존 소비자 제거, 일부 소비자의 장애, 파티션 조정
* 코디네이터
  * 소비자 재조정을 위해 소비자들과 통신하는 브로커
  * 소비자로부터 오는 hearbeat 메시지를 살핌
  * ![](chapter4/image%2012.png)<!-- {"width":418} -->
  * 코디네이터는 자신의 소비자 목록을 유지, 변화가 생기면 새 리더 선출
  * 새 리더는 새 파티션 배치 계획을 만들고 코디네이터에게 전달, 다른 소비자에게 알림
### 상태 저장소
* 소비자에 대한 파티션의 배치 관계
* 각 소비자 그룹이 각 파티션에서 마지막으로 가져간 메시지의 오프셋
* 마지막으로 읽은 오프셋이 6이면, 해당 소비자가 장애나면 다음 소비자가 7부터 읽음![](chapter4/image%2013.png)<!-- {"width":440} -->
* 소비자 상태 정보 데이터 패턴
  * 읽기/쓰기가 빈번, 양은 적음
  * 갱신은 빈번, 삭제는 거의 없음
  * 읽기와 쓰기 연산은 무작위
  * 데이터의 일관성 중요
* 데이터 일관성 및 높은 읽기/쓰기 속도에 대한 요구사항 고려
  * 아파치 주키퍼 같은 키-값 저장소 사용이 바람직함
* [Apache Kafka Zookeeper 제거 이유](https://velog.io/@joyfulbean/Apache-Kafka-Zookeeper-%EC%A0%9C%EA%B1%B0-%EC%9D%B4%EC%9C%A0)
### 메타데이터 저장소
#### 주키퍼
* 주키퍼는 분산 메시지 큐에 매우 우용
* 계층적 키-값 저장소, 분산 시스템에 필수적 서비스
![](chapter4/image%2014.png)<!-- {"width":514} -->
#### 복제
* 디스크에 손상이 발생하면 데이터는 사라짐, 해결하기 위해 복제 기법 사용
* 각 파티션은 3개의 사본을 갖고, 서로 다른 브로커 노드에 분산
* 그림의 짙은 색의 파티션은 해당 파티션의 리더
![](chapter4/image%2015.png)<!-- {"width":629} -->
* 생산자는 파티션의 리더에게만 보냄
* 다른 사본은 리더에서 새 메시지를 지속적으로 가져와 동기화
* 사본 분산 계획은 누가 만들까? 
  * 조정서비스의 도움으로 브로커 노드 가운데 하나가 리더로 선출되면
    * 노드가 사본 분산 계획을 만들고 메타데이터 저장소에 보관함
#### 동기화된 사본 (ISR)
* 복제에서 설명한 여러 사본들을 어떻게 동기화 할까?
![](chapter4/image%2016.png)<!-- {"width":433} -->
* 리더 사본의 합의 오프셋은 13
  * 14, 15의 메시지가 기록되었지만 사본간의 합의가 이루어진 것은 아니다
  * 합의 오프셋의 의미
    * 이 오프셋 이전에 기록된 모든 메세지는 사본 동기화가 끝났다
    * 사본2, 3은 13까지 가져와서 ISR 이 됨, 새 메세지를 가져올 수 있음
    * 사본4는 11까지만 가져와서 ISR이 아님
### ACK=1
* 생산자는 리더가 메시지를 저장하고 나면 바로 ACK 응답을 받는 옵션.
* 메시지를 ACK를 보낸 직후 리더에 장애가 생기면 소실됨.
* 낮은 지연이 중요하면 사용.
### ACK=0
* 수신 확인 메시지를 기다리지 않음.
* 매우 낮은 응답 지연을 위해 손실 감수.
* 메트릭 수집에 사용
### 규모 확장성
* 생산자
  * 그룹단위의 조정에 가담할 필요 없어서 쉬움
  * 새로운 생산자 추가, 삭제 쉽게 달성
* 소비자
  * 소비자 그룹은 서로 독립적, 새 소비자 그룹은 쉽게 삭제 가능
  * 같은 소비자 그룹 내의 소비자
    * 새로 추가/삭제/장애시 리밸런싱 매커니즘
* 브로커
  * 브로커 컨트롤러가 브로커-3이 사라짐 감지
    * 파티션 분산 계획을 새로 만듬
![](chapter4/image%2017.png)<!-- {"width":506} -->
* 브로커-4를 추가할때
![](chapter4/image%2018.png)<!-- {"width":559} -->
* 파티션 추가
  * 파티션 생산자는 브로커와와 통신할때 추가 여부 통지받음
  * 소비자는 리밸런싱 시행
  * 생산자와 소비자의 안정성에 영향 X
    * 아래와같이 새로운 파티션이 추가되면 그 이후 오는 메시지는 신규 메세지에도 저장됨
    * 기존 메세지는 이동하지 않음
![](chapter4/image%2019.png)<!-- {"width":459} -->
* 파티션 삭제
  * 파티션 삭제는 까다로움
  * 파티션 3이 삭제되면 새로운 메세지는 다른 파티션1,2 에만 보관
  * 바로 제거하지 않고, 일정시간 유지, 해당 파티션을 읽고 있는 소비자가 있을 수 있음
![](chapter4/image%2020.png)<!-- {"width":440} -->
### 메시지 전달 방식
* 최대 한번
  * 생산자 : 비동기적, ACK=0, 메시지 전달이 실패해도 다시 시도 안함
  * 소비자 : 소비자는 메시지를 읽고 처리전에 오프셋 먼저 갱신, 소비자가 장애로 죽으면 재소비 안됨
  * 손실 감수시 적합
* 최소 한번
  * ACK=1 또는 ACK=all 구성을 이용
  * 생산자 : 동기적/비동기적으로 보내기, 메시지가 브로커에 전달 되었음을 반드시 확인, 실패시 계속 재시도
  * 소비자 : 데이터를 성공적으로 처리 후에만 오프셋 갱신, 장애시 중복처리될 수 있음
* 정확히 한번
  * 구현이 까다로움, 지불/매매/회계 등 금융 관련에 적합
  * 멱등성이 구현되지 않은 어플리케이션에 사용
### 고급 기능
#### 메시지 필터링
* 예를들어 주문 토픽에는 너무나 방대한 주문관련 이벤트가 발생함 (주문상태 변경, 배송상태 변경, 주문 담당자 변경)
* 결제 시스템은 주문 토픽의 환불 메시지만 관심 있음
* 주문 토픽의 모든 데이터를 소비하면 낭비, 메시지에 태그를 달아 필터링 하는 방법
![](chapter4/image%2021.png)<!-- {"width":480} -->
#### 메시지 지연 전송 및 예약 전송
* 30분뒤에 전달 되어야하는 소비 되어야 하는 메세지
* 브로커 내부의 임시 저장소에 넣어 뒀다가, 시간이 되면 토픽으로 옮기기
![](chapter4/image%2022.png)<!-- {"width":400} -->
> 메시지를 consumer 가 저장한후 30분뒤에 별도의 애플리케이션 배치로 DB를 읽어서 구현했었는데, 카프카로 방법이 있을까?
> 라인에 라이브러리로 구현한 사례 : [Kafka를 이용한 작업 큐 라이브러리 'Decaton' 활용 사례](https://engineering.linecorp.com/ko/blog/decaton-case-studies)